filter(year == 1952)
# Change to put pop on the x-axis and gdpPercap on the y-axis
ggplot(gapminder_1952, aes(x = pop, y = gdpPercap)) +
geom_point()
ggplot(gapminder_1952, aes(x = pop, y = lifeExp)) +
geom_point()
ggplot(gapminder_1952, aes(x = pop, y = lifeExp)) +
geom_point() +
scale_x_log10()
ggplot(gapminder_1952, aes(x = pop, y = gdpPercap)) +
geom_point() +
scale_x_log10() +
scale_y_log10()
ggplot(gapminder_1952, aes(x = pop, y = lifeExp, color = continent, size = gdpPercap)) +
geom_point() +
scale_x_log10()
ggplot(gapminder_1952, aes(x = pop, y = lifeExp)) +
geom_point() +
scale_x_log10() +
facet_wrap(~ continent)
ggplot(gapminder, aes(x = gdpPercap, y = lifeExp, color = continent, size = pop)) +
geom_point() +
scale_x_log10() +
facet_wrap(~ year)
gapminder %>%
group_by(continent, year) %>%
summarize(medianLifeExp = median(lifeExp),
maxGdpPercap = max(gdpPercap))
gapminder %>%
group_by(continent, year) %>%
summarize(medianLifeExp = median(lifeExp),
maxGdpPercap = max(gdpPercap))
ggplot(by_year, aes(x = year, y = medianLifeExp)) +
geom_point() +
expand_limits(y = 0)
by_year_continent <- gapminder %>%
group_by(continent, year) %>%
summarize(medianGdpPercap = median(gdpPercap))
ggplot(by_year_continent, aes(x = year, y = medianGdpPercap, color = continent)) +
geom_point() +
expand_limits(y = 0)
by_continent_2007 <- gapminder %>%
filter(year == 2007) %>%
group_by(continent) %>%
summarize(medianGdpPercap = median(gdpPercap),
medianLifeExp = median(lifeExp))
ggplot(by_continent_2007, aes(x = medianGdpPercap, y = medianLifeExp, color = continent)) +
geom_point()
by_continent_2007 <- gapminder %>%
filter(year == 2007) %>%
group_by(continent) %>%
summarize(medianGdpPercap = median(gdpPercap),
medianLifeExp = median(lifeExp))
by_continent_2007 <- gapminder %>%
filter(year == 2007) %>%
group_by(continent) %>%
summarize(medianGdpPercap = median(gdpPercap),
medianLifeExp = median(lifeExp))
install.packages("googleAnalyticsR")
library(googleAnalyticsR)
ga_auth()
my_accounts <- google_analytics_account_list()
View(my_accounts)
my_id <- 56037355
start_date <- "2018-08-01"
end_date <- "2018-08-31"
df2 <- google_analytics_4(my_id,
date_range = c(start_date, end_date),
metrics = c("sessions"),
dimensions = c("date"))
df2 <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("sessions"),
dimensions = c("date"))
View(df)
View(df2)
install.packages("RGA")
?RGA
authorize()
rga.open(instance = "ga")
install_github("rga", "skardhamar")
install.packages("devtools")
library(devtools)
install_github("rga", "skardhamar")
library(rga)
??rga
ga$getData(xxx,
start.date = "2015-03-30",
end.date = "2015-03-31",
metrics = "ga:totalEvents",
dimensions = "ga:date,ga:customVarValue4,ga:eventCategory,ga:eventAction,ga:eventLabel",
sort = "",
filters = "ga:deviceCategory==desktop",
segment = "",
,batch = TRUE, walk = TRUE
)
ga_data <- google_analytics_4(viewId = "[your view ID]",
date_range = c(Sys.Date()-7, Sys.Date()-1),
metrics = c("users", "sessions","pageviews"),
dimensions = "date",
anti_sample = TRUE)
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","pageviews"),
dimensions = "date",
anti_sample = TRUE)
View(ga_data)
?google_analytics
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","pageviews"),
dimensions = "date",
anti_sample = TRUE,
anti_sample_batches = 1)
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","pageviews"),
dimensions = "date",
anti_sample = TRUE,
anti_sample_batches = "1")
library(googleAnalyticsR)
start_date <- "2018-08-31"
end_date <- "2018-08-01"
my_id <- 56037355
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","pageviews"),
dimensions = "date",
anti_sample = TRUE,
segments = NULL,
anti_sample_batches = 1)
View(ga_data)
start_date <- "2018-08-01"
end_date <- "2018-08-31"
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","pageviews"),
dimensions = "date",
anti_sample = TRUE,
segments = NULL,
anti_sample_batches = 1)
View(ga_data)
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","goal20Completions"),
dimensions = "date", "",
anti_sample = TRUE,
segments = NULL,
anti_sample_batches = 1)
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","goal20Completions"),
dimensions = "date",
anti_sample = TRUE,
segments = NULL,
anti_sample_batches = 1)
ga_data <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","goal20Completions"),
dimensions = "date",
segments = NULL,
anti_sample_batches = 1)
library(googleAnalyticsR)
start_date <- "2018-08-01"
end_date <- "2018-08-31"
my_id <- 56037355
ga_data1 <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","goal20Completions"),
dimensions = "date",
anti_sample = TRUE,
segments = NULL,
anti_sample_batches = 1)
ga_data2 <- google_analytics(my_id,
date_range = c(start_date, end_date),
metrics = c("users", "sessions","goal20Completions"),
dimensions = "date",
segments = NULL,
anti_sample_batches = 1)
View(ga_data1)
View(ga_data2)
install.packages("googleAuthR")
install.packages("googleAuthR")
install.packages("googleAuthR")
q()
install.packages("tensor")
remove.packages("tensor", lib="~/R/win-library/3.5")
devtools::install_github("rstudio/keras")
q()
?make_ga_4_req
??make_ga_4_req
today()
Sys.Date()
Sys.Date()-1
?date_range
??date_range
q()
library(swirl)
swirl()
data(cars)
??cars
?cars
head(cars)
plot(cars)
?plot
plot(x = cars$speed, y = cars$dist)
plot(cars, x = cars$dist, y = cars$speed)
plot(x = cars$dist, y = cars$speed)
plot(Speed = cars$speed, y = cars$dist)
?plot
plot(x = cars$speed, y = cars$dist, xlab = "Speed")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, xlab = "Speed", ylab = "Stopping Distance")
plot(x = cars$speed, y = cars$dist, main = "My Plot")
plot(cars, main = "My Plot")
plot(cars, sub = "My Plot Subtitle")
plot(cars, col = 2)
plot(cars, xlim = c(10, 15))
plot(cars, pch = 2)
data("mtcars")
data(mtcars)
?boxplot
boxplot(mpt ~ cyl, data = mtcars)
boxplot(mpg ~ cyl, data = mtcars)
hist(mtcars$mpg)
q()
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
getwd()
setwd("C:/All-Files/Study&Learning/Udemy/Data Science Academy Master Data Science in R/Section1.4")
install.packages("httr")
library(httr)
r <- GET("https://www.nabler.com")
r
View(r\)
View(r)
r[["status_code"]]
r[["headers"]][["server"]]
r[["request"]]
data <- read.table("week4assignment-outcome-of-care-measures.csv", header = TRUE, sep = ",", na.strings = "NA", stringsAsFactors = FALSE)
data <- data[, c(which(colnames(data) == "Hospital.Name"),
which(colnames(data) == "State"),
which(colnames(data) == "Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack"),
which(colnames(data) == "Hospital.30.Day.Death..Mortality..Rates.from.Heart.Failure"),
which(colnames(data) == "Hospital.30.Day.Death..Mortality..Rates.from.Pneumonia"))]
colnames(data) <- c("hospital.name", "State", "heart.attack", "heart.failure", "pneumonia")
data[data == "Not Available"] <- NA
data$heart.attack <- as.numeric(data$heart.attack)
data$heart.failure <- as.numeric(data$heart.failure)
data$pneumonia <- as.numeric(data$pneumonia)
statelist <- unique(data$State)
outcomelist <- c("heart attack", "heart failure", "pneumonia")
# Check that state and outcome are valid
state <- "AL"
outcome <- "heart attack"
num <- "best"
if(state %in% statelist == FALSE) {
stop("invalid state")
} else if(outcome %in% outcomelist == FALSE) {
stop("invalid outcome")
# If the state and outcome are valid, continue with the program
} else {
# Choose the outcome column to take, subset to the required columns and remove NAs
if(outcome == "heart attack") {
outcomecol <- "heart.attack"
finaldata <- data[, c(1, 2, 3)]
finaldata <- finaldata[complete.cases(finaldata$heart.attack), ]
} else if(outcome == "heart failure") {
outcomecol <- "heart.failure"
finaldata <- data[, c(1, 2, 4)]
finaldata <- finaldata[complete.cases(finaldata$heart.failure), ]
} else {
outcomecol <- "pneumonia"
finaldata <- data[, c(1, 2, 5)]
finaldata <- finaldata[complete.cases(finaldata$pneumonia), ]
}
# Changing best, worst and number function inputs to proper format
if(num == "best") {
num <- 1
} else if(num == "worst") {
num <- nrow(finaldata)
} else if(class(num == "numeric") == TRUE) {
num <- num
}
# Split the data set by state
splitbystate <- split(finaldata, finaldata$State)
View(splitbystate)
ans <- lapply(splitbystate, function(x, num) {
x <- x[order(x[, 3], x$hospital.name), ]
}, num)
View(ans)
return(data.frame(hospital = unlist(ans), state = names(ans)))
}
if(num == "best") {
num <- 1
} else if(num == "worst") {
num <- nrow(finaldata)
} else if(class(num == "numeric") == TRUE) {
num <- num
}
splitbystate <- split(finaldata, finaldata$State)
View(splitbystate)
splitbystate <- split(finaldata, finaldata$State)
if(outcome == "heart attack") {
outcomecol <- "heart.attack"
finaldata <- data[, c(1, 2, 3)]
finaldata <- finaldata[complete.cases(finaldata$heart.attack), ]
} else if(outcome == "heart failure") {
outcomecol <- "heart.failure"
finaldata <- data[, c(1, 2, 4)]
finaldata <- finaldata[complete.cases(finaldata$heart.failure), ]
} else {
outcomecol <- "pneumonia"
finaldata <- data[, c(1, 2, 5)]
finaldata <- finaldata[complete.cases(finaldata$pneumonia), ]
}
if(num == "best") {
num <- 1
} else if(num == "worst") {
num <- nrow(finaldata)
} else if(class(num == "numeric") == TRUE) {
num <- num
}
splitbystate <- split(finaldata, finaldata$State)
requiredPackages <- c("googleAnalyticsR", "tidyr", "dplyr", "openxlsx", "XLConnect")
version()
version
library(fractribution.data)
library(fractribution.model)
path_customer_map
View
View(path_customer_map)
example_path_customer_map
head(example_path_summary)
fractional_attribution <- attribution_fit(example_path_summary)
fractional_attribution <- attribution_fit(example_path_summary, path_level_only = T)
View(fractional_attribution)
install.packages("Forecast")
Y
install.packages("forecast")
install.packages("lubridate")
install.packages("dplyr")
install.packages("ttr")
install.packages("TTR")
install.packages("DMWR")
install.packages("DMwR")
install.packages("Tseries")
install.packages("tseries")
exit
q()
if(require(forecast)){library(forecast)} else {install.packages("forecast");library(forecast)}
if(require(tseries)){library(tseries)} else {install.packages("tseries");library(tseries)}
if(require(aTSA)){library(aTSA)} else {install.packages("aTSA");library(aTSA)}
if(require(plotly)){library(plotly)} else {install.packages("plotly");library(plotly)}
if(require(Hmisc)){library(Hmisc)} else {install.packages("Hmisc");library(Hmisc)}
if(require(dplyr)){library(dplyr)} else {install.packages("dplyr");library(dplyr)}
library(knitr)
library(tm)
library(forecast)
data<-read.csv(file.choose(),header=T,na.strings = c(""," "),stringsAsFactors = F)
data<-read.csv(file.choose(),header=T,na.strings = c(""," "),stringsAsFactors = F)
data$Month <- factor(data$Month, levels = data[["Month"]])
#Splitting into test and train by logical split by seasonality (for example, complete year)
data_train<-data[1:72,2]
data_test<-data[73:84,2]
#Converting data to a time-series
volume_ts<-ts(data_train,start = c(2009,1),end=c(2014,12),frequency = 12)
# Decomposing to look at the seasonal, trend and irregular components
comp <- stl(volume_ts, s.window = "periodic")
plot(comp)
plot.ts(volume_ts)
# Performing a Unit Root Test - Augmented Dickey Fuller (ADF) test
tseries::adf.test(volume_ts)
tseries::adf.test(diff(volume_ts,differences = 1))
plot(diff(volume_ts),ylab="Differenced",type="l")
# Decomposing to look at the seasonal, trend and irregular components
comp <- stl(volume_ts, s.window = "periodic")
plot(comp)
plot.ts(volume_ts)
# Performing a Unit Root Test - Augmented Dickey Fuller (ADF) test
tseries::adf.test(volume_ts)
tseries::adf.test(diff(volume_ts,differences = 1))
diff(volume_ts)
?tseries
??tseries
?adf.test
install.packages("rvest")
library(rvest)
?httr::status_code()
options(scipen = 999)
options(scipen = 999)
4000/1386400000
alarm()
alarm()
install.packages("beepr")
library(beepr)
beep()
beep()
?beep
beep(4)
beep(5)
beep(7)
beep(9)
beep(8)
beep(11)
getwd()
# Question 1
# The American Community Survey distributes downloadable data about United States communities. Download the
# 2006 microdata survey about housing for the state of Idaho using download.file() from here:
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
# and load the data into R. The code book, describing the variable names is here:
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf
# How many properties are worth $1,000,000 or more?
setwd("C:/All-Files/Study&Learning/Coursera/DataScience/GettingAndCleaningData/Week1")
getwd()
data <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
View(data)
milplus <- filter(data, VAL == 24)
?filter
library(dplyr)
data <- read.csv("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
milplus <- filter(data, VAL == 24)
nrow(milplus)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", "dataset.xlsx", method = "curl")
dat <- readxl::read_xlsx("dataset.xlsx", range = "NGAP Sample Data!G18:N23")
sum(dat$Zip*dat$Ext,na.rm=T)
theurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileURL <- getURL(url = theurl)
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
library(XML)
theurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileURL <- getURL(url = theurl)
??getURL
??xmlTree
library(XML, RCurl)
theurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileURL <- getURL(url = theurl)
library(RCurl)
theurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
fileURL <- getURL(url = theurl)
doc <- xmlTreeParse(fileURL, useInternalNodes = TRUE)
rootNode <- xmlRoot(doc)
zipcodes <- xpathSApply(rootNode, "//zipcode", xmlValue)
View(zipcodes)
class(zipcodes)
View(zipcodes)
zipcodes <- as.data.frame(zipcodes)
class(zipcodes)
View(zipcodes)
zipcodes[1]
filter(zipcodes$zipcodes == "21231")
zipcodes$zipcodes <- as.data.frame(zipcodes$zipcodes)
filter(zipcodes$zipcodes == "21231")
filter(zipcodes$zipcodes == 21231)
zipcodes[zipcodes == 21231]
nrows(zipcodes[zipcodes == 21231])
nrow(zipcodes[zipcodes == 21231])
ncol(zipcodes[zipcodes == 21231])
class(zipcodes)
View(zipcodes)
zipcodes <- xpathSApply(rootNode, "//zipcode", xmlValue)
View(zipcodes)
class(zipcodes)
?count
count(zipcodes)
count(zipcodes[zipcodes == 21231])
View(zipcodes)
zipcodes <- as.numeric(zipcodes)
class(zipcodes)
zipcodes[zipcodes == 21231]
length(zipcodes[zipcodes == 21231])
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "dataset2.xlsx", method = "curl")
?fread
??fread
library(data.table)
?fread
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "dataset2.csv", method = "curl")
DT <- fread(file = "dataset2.csv", sep = ",", header = TRUE)
View(DT)
View(DT)
system.time()
View(DT)
DT[0,]
headernames <- DT[0,]
headernames
headernames <- as.character(DT[0,])
headernames
system.time(rowMeans(DT)[DT$SEX == 1]; rowMeans(DT)[DT$SEX == 2])
system.time(rowMeans(DT)[DT$SEX == 1]) + system.time(rowMeans(DT)[DT$SEX == 2])
system.time(rowMeans(DT)[DT$SEX == 1])
system.time(rowMeans(DT)[DT$SEX == 2])
class(system.time(rowMeans(DT)[DT$SEX == 2]))
?system.time
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
DT[,mean(pwgtp15),by=SEX]
mean(DT$pwgtp15,by=DT$SEX)
??by
